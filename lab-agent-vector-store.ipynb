{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
      "metadata": {
        "id": "efad6479-7fb1-40c4-8610-8963f8de307f"
      },
      "source": [
        "# Lab | Agent & Vector store\n",
        "\n",
        "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
        "\n",
        "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b24990",
      "metadata": {
        "id": "68b24990"
      },
      "source": [
        "# Combine agents and vector stores\n",
        "\n",
        "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
        "\n",
        "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b22020a",
      "metadata": {
        "id": "9b22020a"
      },
      "source": [
        "## Create the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
      "metadata": {
        "tags": [],
        "collapsed": true,
        "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
        "outputId": "863c0fe4-3253-4699-be0d-9f51e36de858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.7.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.4.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from chromadb)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=8a371fe357b6c73c5eac6c956dbd74a58d690f67d65ae740047108a46b5584a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, ujson, python-multipart, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, h11, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpcore, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.1.0 kubernetes-30.1.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.18.1 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.6 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "SGP8vYx3tCSz",
        "outputId": "38c86d05-8449-4ff6-e664-0b5843e6b299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SGP8vYx3tCSz",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.11)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain_openai)\n",
            "  Downloading openai-1.35.9-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (2.7.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (8.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, openai, langchain_openai\n",
            "Successfully installed langchain_openai-0.1.14 openai-1.35.9 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
      "metadata": {
        "tags": [],
        "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
      "metadata": {
        "tags": [],
        "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#from dotenv import load_dotenv, find_dotenv\n",
        "#_ = load_dotenv(find_dotenv())\n",
        "\n",
        "#OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
        "#HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY_Ironhack')\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
      "metadata": {
        "tags": [],
        "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "0b7b772b",
      "metadata": {
        "tags": [],
        "id": "0b7b772b"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "relevant_parts = []\n",
        "for p in Path(\".\").absolute().parts:\n",
        "    relevant_parts.append(p)\n",
        "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
        "        break\n",
        "doc_path = str(Path(*relevant_parts) / \"/content/sonnets.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f2675861",
      "metadata": {
        "tags": [],
        "id": "f2675861"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(doc_path)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"sonnets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bc5403d4",
      "metadata": {
        "tags": [],
        "id": "bc5403d4"
      },
      "outputs": [],
      "source": [
        "state_of_union = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1431cded",
      "metadata": {
        "tags": [],
        "id": "1431cded",
        "outputId": "8dcfda3e-2f03-40fd-9acd-e8d721d6abef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "915d3ff3",
      "metadata": {
        "tags": [],
        "id": "915d3ff3"
      },
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "96a2edf8",
      "metadata": {
        "tags": [],
        "id": "96a2edf8",
        "outputId": "c2562aae-be2c-41bc-c807-9e36402b4df8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2134, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2470, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1259, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1302, which is longer than the specified 1000\n"
          ]
        }
      ],
      "source": [
        "docs = loader.load()\n",
        "ruff_texts = text_splitter.split_documents(docs)\n",
        "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
        "ruff = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a6c031",
      "metadata": {
        "id": "c0a6c031"
      },
      "source": [
        "## Create the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eb142786",
      "metadata": {
        "tags": [],
        "id": "eb142786"
      },
      "outputs": [],
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.agents import AgentType, Tool, initialize_agent\n",
        "from langchain_openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "850bc4e9",
      "metadata": {
        "tags": [],
        "id": "850bc4e9"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"State of Union QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fc47f230",
      "metadata": {
        "tags": [],
        "id": "fc47f230",
        "outputId": "3213fd1e-c6ea-4259-c252-3fd2a53ab4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, max_iterations=3, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "10ca2db8",
      "metadata": {
        "tags": [],
        "id": "10ca2db8",
        "outputId": "13d508e3-49ff-49a5-f55d-dc2a50c2c860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
            "Action: State of Union QA System\n",
            "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
              " 'output': \"Biden nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e91b811",
      "metadata": {
        "tags": [],
        "id": "4e91b811",
        "outputId": "70090e31-3917-49d0-93b3-53ee833f56da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m You should always think about the differences between ruff and flake8\n",
            "Action: Ruff QA System\n",
            "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff can replace multiple Flake8 plugins, has a larger rule set, and can automatically fix its own lint violations. It also supports Python versions from 3.7 onwards and does not require the installation of Rust. Additionally, Ruff can be used independently as a linter or formatter, and can be used alongside a type checker for more comprehensive error detection.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Ruff offers more features and flexibility compared to flake8, making it a better choice for linting and formatting Python code.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Why use ruff over flake8?',\n",
              " 'output': 'Ruff offers more features and flexibility compared to flake8, making it a better choice for linting and formatting Python code.'}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\"Why use ruff over flake8?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results with updated code\n",
        "agent.invoke(\"Why use ruff over flake8?\")"
      ],
      "metadata": {
        "id": "00jEEPblwbAj",
        "outputId": "0cbf17c6-c38d-4c29-8e63-2d058a852bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "00jEEPblwbAj",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Ruff is a python linter that has some unique features compared to flake8, so it's worth exploring the differences.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"What are the unique features of ruff compared to flake8?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff has over 800 implemented rules, compared to Flake8's ~409 rules. Ruff also has a different rule code and prefix system to minimize conflicts and allow for easier toggling of individual plugins. Additionally, Ruff does not support custom lint rules, but instead re-implements popular Flake8 plugins in Rust. Ruff also has some minor incompatibilities with Flake8 plugins, but many users have successfully switched from Flake8 to Ruff. Ruff also has the ability to automatically fix its own lint violations, unlike Flake8.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m These unique features of Ruff make it a strong contender for a python linter.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"What are the benefits of using Ruff over Flake8?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff offers a larger rule set, compatibility with Black, and automatic fixing of lint violations. It also supports Python 3.7 onwards, while Flake8 only supports Python 2. Additionally, Ruff does not require the installation of Rust, unlike Flake8.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m After comparing the unique features and benefits of Ruff, I can make an informed decision on whether to use it over Flake8.\n",
            "Final Answer: Ruff offers a larger rule set, compatibility with Black, automatic fixing of lint violations, and support for Python 3.7 onwards, making it a strong contender for a python linter.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Why use ruff over flake8?',\n",
              " 'output': 'Ruff offers a larger rule set, compatibility with Black, automatic fixing of lint violations, and support for Python 3.7 onwards, making it a strong contender for a python linter.'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shakespeare's Sonnets**"
      ],
      "metadata": {
        "id": "REY7CvjC4RfA"
      },
      "id": "REY7CvjC4RfA"
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "relevant_parts = []\n",
        "for p in Path(\".\").absolute().parts:\n",
        "    relevant_parts.append(p)\n",
        "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
        "        break\n",
        "doc_path = str(Path(*relevant_parts) / \"/content/sonnets.txt\")"
      ],
      "metadata": {
        "id": "gAIGL0_h5jSl"
      },
      "id": "gAIGL0_h5jSl",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(doc_path)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"sonnets\")"
      ],
      "metadata": {
        "id": "y5egQISt5j0l"
      },
      "id": "y5egQISt5j0l",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sonnets = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "eUp2hsoz5mP9"
      },
      "id": "eUp2hsoz5mP9",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")\n",
        "\n",
        "docs = loader.load()\n",
        "ruff_texts = text_splitter.split_documents(docs)\n",
        "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
        "ruff = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "9Ap_hTyz5n-d",
        "outputId": "7103f87b-fb3d-4440-e0da-e566b59a6af2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9Ap_hTyz5n-d",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2134, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2470, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1259, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1302, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Shakespeare Sonnets QA System\",\n",
        "        func=sonnets.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare Sonnets. Input should be a fully formed question.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "A913Ja-X4O_Z"
      },
      "id": "A913Ja-X4O_Z",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, max_iterations=3, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "rqAJkKtc4UrJ"
      },
      "id": "rqAJkKtc4UrJ",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\n",
        "    \"What themes are prevalent in Shakespeare's sonnets, and how do they reflect the concerns of the Elizabethan era?\"\n",
        ")"
      ],
      "metadata": {
        "id": "_x5s4vaP4Ycz",
        "outputId": "16a96d4e-38ab-4d7b-9f66-7bc902eb3e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_x5s4vaP4Ycz",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m It would be helpful to use a tool that is specifically designed for answering questions about Shakespeare's sonnets.\n",
            "Action: Shakespeare Sonnets QA System\n",
            "Action Input: \"What themes are prevalent in Shakespeare's sonnets, and how do they reflect the concerns of the Elizabethan era?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Some prevalent themes in Shakespeare's sonnets include love, beauty, mortality, and the power of language. These themes reflect the concerns of the Elizabethan era, which was characterized by a fascination with love and beauty, as well as a preoccupation with the fleeting nature of life and the desire for immortality. The use of language and poetry to preserve and immortalize love and beauty was also a common theme in Elizabethan literature. Additionally, the fear of mortality and the inevitability of time's passing were prevalent concerns in this era, as the Elizabethans were living in a time of great political and social change.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This information is helpful, but I also want to know more about the historical context of Shakespeare's sonnets.\n",
            "Action: Shakespeare Sonnets QA System\n",
            "Action Input: \"What was the historical context of Shakespeare's sonnets?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The historical context of Shakespeare's sonnets is that they were written during the Elizabethan era in England, and were dedicated to a mysterious \"Mr. W.H.\" who is believed to be the inspiration for the poems. The sonnets were published in 1609 and are considered to be some of the greatest works of English literature. They explore themes of love, beauty, and mortality, and are believed to have been written for a young man, possibly a patron of Shakespeare's.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I also want to make sure my writing is up to par with the standards of the Elizabethan era.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"How can I ensure my writing meets the standards of the Elizabethan era?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m To ensure your writing meets the standards of the Elizabethan era, you should familiarize yourself with the language and style of the time period. This may involve reading works by famous Elizabethan writers such as William Shakespeare, Christopher Marlowe, and Ben Jonson. Additionally, studying the grammar and vocabulary used during this time period can also help you emulate the writing style of the era. It may also be helpful to consult with a literature or history expert who can provide further guidance and resources.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What themes are prevalent in Shakespeare's sonnets, and how do they reflect the concerns of the Elizabethan era?\",\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\")"
      ],
      "metadata": {
        "id": "EcaKTDdw4rGt",
        "outputId": "9103c898-32e3-4812-e420-23c7c0e190e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EcaKTDdw4rGt",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Shakespeare Sonnets QA System to answer this question.\n",
            "Action: Shakespeare Sonnets QA System\n",
            "Action Input: \"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Shakespeare uses the imagery of a summer's day to compare the beauty of the subject to the fleeting nature of the season. He also uses the metaphor of eternal summer to represent the subject's everlasting beauty and the idea that their beauty will never fade.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Shakespeare uses imagery and metaphor in Sonnet 18 to convey the message that the subject's beauty is eternal and will never fade. \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\",\n",
              " 'output': \"Shakespeare uses imagery and metaphor in Sonnet 18 to convey the message that the subject's beauty is eternal and will never fade.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What role does the concept of time play in Shakespeare's sonnets, and how does the poet address its impact on beauty and love?\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "5wBOvCt_52hA",
        "outputId": "51af1760-09cd-4044-cdf8-c32beae9cd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5wBOvCt_52hA",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m It would be helpful to use the Shakespeare Sonnets QA System to answer this question.\n",
            "Action: Shakespeare Sonnets QA System\n",
            "Action Input: \"What role does time play in Shakespeare's sonnets? How does the poet address its impact on beauty and love?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Time is a major theme in Shakespeare's sonnets, as the poet reflects on the fleeting nature of beauty and the inevitability of aging and decay. He compares human life to plants, which grow and eventually wither away, and warns his beloved to beware of the power of time to take away their youth and beauty. However, he also offers a solution to this problem by suggesting that through love, one can transcend the limitations of time and find eternal beauty.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I have a better understanding of the role of time in Shakespeare's sonnets.\n",
            "Final Answer: The concept of time plays a significant role in Shakespeare's sonnets, as the poet explores its impact on beauty and love and offers a solution through the power of love.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What role does the concept of time play in Shakespeare's sonnets, and how does the poet address its impact on beauty and love?\",\n",
              " 'output': \"The concept of time plays a significant role in Shakespeare's sonnets, as the poet explores its impact on beauty and love and offers a solution through the power of love.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRE6dbXH56yo"
      },
      "id": "JRE6dbXH56yo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "787a9b5e",
      "metadata": {
        "id": "787a9b5e"
      },
      "source": [
        "## Use the Agent solely as a router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9161ba91",
      "metadata": {
        "id": "9161ba91"
      },
      "source": [
        "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
        "\n",
        "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f59b377e",
      "metadata": {
        "tags": [],
        "id": "f59b377e"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Sonnets QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8615707a",
      "metadata": {
        "tags": [],
        "id": "8615707a"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "36e718a9",
      "metadata": {
        "tags": [],
        "id": "36e718a9",
        "outputId": "c6888833-a17f-48ac-9dac-0ade7fca91f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer this question.\n",
            "Action: State of Union QA System\n",
            "Action Input: \"What did Biden say about Ketanji Brown Jackson in the state of the union address?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What did biden say about ketanji brown jackson in the state of the union address?',\n",
              " 'output': \" Biden said that he nominated Ketanji Brown Jackson for the United States Supreme Court and praised her as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"What did biden say about ketanji brown jackson in the state of the union address?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "edfd0a1a",
      "metadata": {
        "tags": [],
        "id": "edfd0a1a",
        "outputId": "f70fd22d-b480-4f4f-f7cf-9305fa6a3eab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Ruff is a python linter that has some unique features compared to flake8, so it may be useful in certain situations.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"Why use ruff over flake8?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff can replace multiple Flake8 plugins, has a larger rule set, and can automatically fix its own lint violations. It also supports Python versions from 3.7 onwards and does not require the installation of Rust. Additionally, Ruff can be used independently as a linter or formatter, and can be used alongside a type checker for more comprehensive error detection.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Why use ruff over flake8?',\n",
              " 'output': ' Ruff can replace multiple Flake8 plugins, has a larger rule set, and can automatically fix its own lint violations. It also supports Python versions from 3.7 onwards and does not require the installation of Rust. Additionally, Ruff can be used independently as a linter or formatter, and can be used alongside a type checker for more comprehensive error detection.'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "agent.invoke(\"Why use ruff over flake8?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shakespeare Sonnets**"
      ],
      "metadata": {
        "id": "SrY5XulL5-hE"
      },
      "id": "SrY5XulL5-hE"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Sonnets QA System\",\n",
        "        func=sonnets.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare. Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\",\n",
        "        return_direct=True,\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "UXI3ph_K5-Oy"
      },
      "id": "UXI3ph_K5-Oy",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "TH6Hvu276Bzu"
      },
      "id": "TH6Hvu276Bzu",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What role does the concept of time play in Shakespeare's sonnets, and how does the poet address its impact on beauty and love?\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "X6QDcyVP6GiA",
        "outputId": "d0a681d1-8b13-478e-ea21-b5862c6ed00b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X6QDcyVP6GiA",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to answer this question.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"What role does the concept of time play in Shakespeare's sonnets, and how does the poet address its impact on beauty and love?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m The concept of time is a recurring theme in Shakespeare's sonnets, as the poet reflects on the fleeting nature of beauty and the inevitability of aging and death. In Sonnet XVI, the poet compares human life to plants that grow and eventually wither away, and in Sonnet XIII, he laments the passing of time and its effect on beauty. However, the poet also offers a solution to this struggle against time, suggesting that through procreation, one can leave a lasting legacy and defy the inevitable decay of beauty.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What role does the concept of time play in Shakespeare's sonnets, and how does the poet address its impact on beauty and love?\",\n",
              " 'output': \" The concept of time is a recurring theme in Shakespeare's sonnets, as the poet reflects on the fleeting nature of beauty and the inevitability of aging and death. In Sonnet XVI, the poet compares human life to plants that grow and eventually wither away, and in Sonnet XIII, he laments the passing of time and its effect on beauty. However, the poet also offers a solution to this struggle against time, suggesting that through procreation, one can leave a lasting legacy and defy the inevitable decay of beauty.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\n",
        "    \"What themes are prevalent in Shakespeare's sonnets, and how do they reflect the concerns of the Elizabethan era?\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "k2AchINx6Ike",
        "outputId": "5f9262df-ade5-4d0d-8754-5f61f5da7dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k2AchINx6Ike",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m It would be helpful to use the Sonnets QA System to answer this question.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"What themes are prevalent in Shakespeare's sonnets, and how do they reflect the concerns of the Elizabethan era?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Some prevalent themes in Shakespeare's sonnets include love, beauty, mortality, and the power of language. These themes reflect the concerns of the Elizabethan era, which was characterized by a fascination with love and beauty, as well as a preoccupation with the fleeting nature of life and the desire for immortality. The use of language and poetry as a means of preserving love and beauty also reflects the importance placed on literature and the arts during this time period. Additionally, the sonnets often explore the complexities of relationships and the societal expectations placed on individuals, reflecting the strict social norms and expectations of the Elizabethan era.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What themes are prevalent in Shakespeare's sonnets, and how do they reflect the concerns of the Elizabethan era?\",\n",
              " 'output': \" Some prevalent themes in Shakespeare's sonnets include love, beauty, mortality, and the power of language. These themes reflect the concerns of the Elizabethan era, which was characterized by a fascination with love and beauty, as well as a preoccupation with the fleeting nature of life and the desire for immortality. The use of language and poetry as a means of preserving love and beauty also reflects the importance placed on literature and the arts during this time period. Additionally, the sonnets often explore the complexities of relationships and the societal expectations placed on individuals, reflecting the strict social norms and expectations of the Elizabethan era.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\")"
      ],
      "metadata": {
        "id": "tat8W4Xo6HnC",
        "outputId": "60647269-8f5b-4cb4-b6d9-966b940124a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tat8W4Xo6HnC",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to answer this question.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Shakespeare uses the imagery of a summer's day to compare the beauty of the subject to the fleeting nature of the season. He also uses the metaphor of eternal summer to represent the subject's everlasting beauty and the idea that their beauty will never fade.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\",\n",
              " 'output': \" Shakespeare uses the imagery of a summer's day to compare the beauty of the subject to the fleeting nature of the season. He also uses the metaphor of eternal summer to represent the subject's everlasting beauty and the idea that their beauty will never fade.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a0cbbe",
      "metadata": {
        "id": "49a0cbbe"
      },
      "source": [
        "## Multi-Hop vector store reasoning\n",
        "\n",
        "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d397a233",
      "metadata": {
        "tags": [],
        "id": "d397a233"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"State of Union QA System\",\n",
        "        func=state_of_union.run,\n",
        "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06157240",
      "metadata": {
        "tags": [],
        "id": "06157240"
      },
      "outputs": [],
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b492b520",
      "metadata": {
        "tags": [],
        "id": "b492b520",
        "outputId": "e0f072c8-1bd0-4038-9094-c35f0eb52230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Ruff QA System to answer the first question and the State of Union QA System to answer the second question.\n",
            "Action: Ruff QA System\n",
            "Action Input: What tool does ruff use to run over Jupyter Notebooks?\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff integrates with nbQA, a tool for running linters and code formatters over Jupyter Notebooks.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to answer the second question.\n",
            "Action: State of Union QA System\n",
            "Action Input: Did the president mention that tool in the state of the union?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\n",
            "No, the president did not mention a specific tool in the state of the union.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: No, the president did not mention a specific tool in the state of the union.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?',\n",
              " 'output': 'No, the president did not mention a specific tool in the state of the union.'}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    \"What tool does ruff use to run over Jupyter Notebooks? Did the president mention that tool in the state of the union?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Sonnets QA System\",\n",
        "        func=sonnets.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare. Input should be a fully formed question.\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Ruff QA System\",\n",
        "        func=ruff.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question, not referencing any obscure pronouns from the conversation before.\",\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "xdUUvcxH6N4A"
      },
      "id": "xdUUvcxH6N4A",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the agent. We will use the default agent type here.\n",
        "# See documentation for a full list of options.\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "GlrevZ0o6hQ1"
      },
      "id": "GlrevZ0o6hQ1",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\")"
      ],
      "metadata": {
        "id": "ugONzic_7n3I",
        "outputId": "85f1dcde-d6dd-4d44-91f7-fc59adcfc087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ugONzic_7n3I",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Sonnets QA System to answer this question.\n",
            "Action: Sonnets QA System\n",
            "Action Input: \"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m Shakespeare uses imagery and metaphor to compare the fleeting nature of a summer's day to the eternal beauty of the subject of the poem. He also uses the image of winter to represent the eventual decline of beauty, but suggests that the subject's beauty will live on through his words.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Shakespeare uses imagery and metaphor to compare the fleeting nature of a summer's day to the eternal beauty of the subject of the poem. He also uses the image of winter to represent the eventual decline of beauty, but suggests that the subject's beauty will live on through his words.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"How does Shakespeare use imagery and metaphor in Sonnet 18 (Shall I compare thee to a summers day?) to convey the poem's message?\",\n",
              " 'output': \"Shakespeare uses imagery and metaphor to compare the fleeting nature of a summer's day to the eternal beauty of the subject of the poem. He also uses the image of winter to represent the eventual decline of beauty, but suggests that the subject's beauty will live on through his words.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What's ruff and where to use it?\")"
      ],
      "metadata": {
        "id": "U80R8b_97o--",
        "outputId": "44f528c1-d5fd-48cb-d5f0-56c263f8644a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "U80R8b_97o--",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Ruff is a python linter that helps identify and fix errors in code. It can be used in any python project.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"What is ruff and where can it be used?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff is a tool that can be used for linting and formatting Python code. It can be installed and used on any Python version from 3.7 onwards.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This is helpful information, but it doesn't fully answer the question.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"What is the purpose of ruff?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m The purpose of Ruff is to provide a linter and formatter for Python code that is compatible with Flake8 plugins, but also has its own unique rule set and limitations. It also aims to minimize conflicts between plugins and allow for easy toggling of individual plugins.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This provides more insight into the specific purpose of ruff, but still doesn't fully answer the question.\n",
            "Action: Ruff QA System\n",
            "Action Input: \"Where can ruff be used?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m Ruff is available as ruff on PyPI, so it can be installed and used in any Python project.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This is the same information as before, but it does answer the question.\n",
            "Final Answer: Ruff is a python linter that can be used in any python project. It is available on PyPI and aims to provide a linter and formatter for Python code with its own unique rule set and compatibility with Flake8 plugins.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What's ruff and where to use it?\",\n",
              " 'output': 'Ruff is a python linter that can be used in any python project. It is available on PyPI and aims to provide a linter and formatter for Python code with its own unique rule set and compatibility with Flake8 plugins.'}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}